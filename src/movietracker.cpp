

#include <iostream>
#include <fstream>
#include <vector>
#include <string>
#include <stdio.h>
#include <iostream>
#include <sys/time.h>
#include <unistd.h>
#include <sstream>
#include <stdlib.h>
#include <inttypes.h>
#include <glob.h>
#include <vector>
#include <fcntl.h>
#include <linux/kd.h>
#include <sys/ioctl.h>
#include <boost/algorithm/string.hpp> // include Boost, a C++ library
#include <sys/stat.h>
#include <sys/types.h>
#include <utime.h>
#include <stdlib.h>
#include <fcntl.h>
#include <errno.h>
#include <unistd.h>
#include <syslog.h>


#include <fstream>
#include <iomanip>
#include <unistd.h>
#include <cstdio>
#include <errno.h>
#include <linux/videodev2.h>
#include <stdint.h>
#include <stdio.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <unistd.h>

#include <vector>
#include <stdio.h>



//openCV
#include <opencv2/opencv.hpp>
#include <opencv/cv.hpp>
#include <opencv2/videoio.hpp>
#include "opencv2/imgcodecs.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/core/core.hpp"


#include <iostream>
#include <stdio.h>
#include <stdlib.h>


#include "cgicc/Cgicc.h"
#include "cgicc/HTTPHTMLHeader.h"
#include "cgicc/HTMLClasses.h"

#include <boost/property_tree/ptree.hpp>
#include <boost/property_tree/json_parser.hpp>
#include <boost/lexical_cast.hpp>
#include <boost/foreach.hpp>

using namespace std;
using namespace cgicc;
using namespace cv;
using boost::property_tree::ptree;
using boost::property_tree::read_json;
using boost::property_tree::write_json;



const Scalar SCALAR_BLACK = Scalar(0.0,0.0,0.0);
const Scalar SCALAR_WHITE = Scalar(255.0,255.0,255.0);
const Scalar SCALAR_BLUE = Scalar(255.0,0.0,0.0);
const Scalar SCALAR_GREEN = Scalar(0.0,255.0,0.0);
const Scalar SCALAR_RED = Scalar(0.0,0.0,255.0);



// Global variables
Mat myframe; //current frame
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
int keyboard; //input from keyboard
void help();
void processVideo(string videoFilename, float learningrate, int daynum);
void processImages(char* firstFrameFilename);

int main(int argc, char* argv[])
{

    //check for the input parameter correctness
    if(argc != 5) {
        cerr <<"Incorret input list" << endl;
        cerr <<"exiting..." << endl;
        return EXIT_FAILURE;
    }
    //create GUI windows
    namedWindow("Frame");
  //  namedWindow("FG Mask MOG 2");
    namedWindow("Simple Ass BS");
 //namedWindow("keypoints");
	
    //create Background Subtractor objects
    pMOG2 = createBackgroundSubtractorKNN(); //MOG2 approach

			
    if(strcmp(argv[1], "-vid") == 0) {
        //input data coming from a video

	int startday = atoi(argv[3]);
	int endday= atoi(argv[4]);
	for (int i=startday; i <= endday; i++){
		stringstream ms;
		ms << argv[2] << "day" << i << ".avi";
	        processVideo(ms.str(), 0.01,i);
	}//end for each day
    }
    else if(strcmp(argv[1], "-img") == 0) {
        //input data coming from a sequence of images
        processImages(argv[2]);
    }
    else {
        //error in reading input parameters
        cerr <<"Please, check the input parameters." << endl;
        cerr <<"Exiting..." << endl;
        return EXIT_FAILURE;
    }
    //destroy GUI windows
    destroyAllWindows();
    return EXIT_SUCCESS;
}


bool emptypixel(int x, int y){

}//end test for empty pixels


unsigned char readpixelmap(int x, int y){


}//end readpixelmap 

int setpixelmap(int setvalue){

}//end set pixelmap

void flood(int x, int y, int setvalue) {

	if (readpixelmap(x,y) == setvalue) return;
	if (emptypixel(x,y)) return;

	if (!readpixelmap(x,y)){ 
		setpixelmap(setvalue);
		
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x+1,y)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x,y+1)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x+1,y+1)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x-1,y)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x,y-1)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x-1,y-1)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x-1,y+1)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet
	if (!readpixelmap(x+1,y-1)){ 
		setpixelmap(setvalue);
	}//end if pixel hadn't been assigned yet

}//end flood the non zero pixels that are connected

void defineBlobs(char* imageFilename){

	Mat connectivity;
	Mat sourceimage;
	int blobcounter=0;

	Size s = sourceimage.size();

	int imageheight = s.height;
	int imagewidth = s.width;

	//interate over all pixels in an image_and define their connectivity
	for (int j=0; j < imageheight; j++){	
		for (int i=0; i < imagewidth; i++) {
			if (!emptypixel(i,j)){
				flood(i,j,blobcounter++);
			}//end if pixel has value
		}//end for each row
	}//end for each column


}//end defineBlobs


void processVideo(string videoFilename, float learningrate, int daynum) {

	double alpha = 0.5; //set blend value

    //create the capture object
    	VideoCapture capture(videoFilename.c_str());
	Mat tester;
	Mat lastrun = imread("movementmask.png");
	Mat wellmask = imread("mask.png");


/*

// Setup SimpleBlobDetector parameters.
	SimpleBlobDetector::Params params;
	 
	// Change thresholds
	params.minThreshold = 10;
	params.maxThreshold = 255;
	 
	// Filter by Area.
	params.filterByArea = true;
	params.minArea = 10;
	params.maxArea =500;
	
	// Filter by Circularity
	params.filterByCircularity = false;
	params.minCircularity = 0.1;
	 
	// Filter by Convexity
	params.filterByConvexity = false;
	params.minConvexity = 0.87;
	 
	// Filter by Inertia
	params.filterByInertia = true;
	params.minInertiaRatio = 0.1;

	// Filter by interblob distance
	params.minDistBetweenBlobs = 50;
	 
	// Set up the detector with default parameters.
	cv::Ptr<cv::SimpleBlobDetector> detector = cv::SimpleBlobDetector::create(params); 
 
	// Detect blobs.
	std::vector<KeyPoint> movementkeypoints;
	lastrun=lastrun-wellmask;
	blur( lastrun, lastrun, Size(5,5) );
	detector->detect( lastrun, movementkeypoints);


 
	// Draw detected blobs as red circles.
	// DrawMatchesFlags::DRAW_RICH_KEYPOINTS flag ensures the size of the circle corresponds to the size of blob
	Mat im_with_keypoints;
	drawKeypoints( lastrun, movementkeypoints, im_with_keypoints, Scalar(255,255,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );

	imwrite("blobs.png",im_with_keypoints);

*/







	VideoWriter output;
	stringstream filename;
	filename << "merged.avi";






//create traces
	Mat deathmask;
	Mat arnold; 
	Mat blended;
	bool firstframe=true;


    if(!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open video file: " << videoFilename << endl;
        return;
    }
	capture >> tester;	

 	Mat coloroutput = (Mat::zeros(tester.size(),CV_8UC3));; 
	bool done =false;

	Size size = coloroutput.size();

	//output.open(filename.str().c_str(), VideoWriter::fourcc('M', 'P', '4', '2'),
//			capture.get(CAP_PROP_FPS), size, true);
//

    //read input data. ESC or 'q' for quitting
    while( (char)keyboard != 'q' && (char)keyboard != 27 && !done ){
        //read the current frame
        if(!capture.read(myframe)) {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
	    done=true;


	    Mat img, img_edge, labels, centroids, img_color, stats;



		  int i, nccomps = cv::connectedComponentsWithStats (
			arnold, 
			labels,
			stats, 
			centroids
		  );
		  cout << "Total Raw Connected Components Detected: " << nccomps << endl;
		  int filteredcomponents=nccomps;

		  vector<cv::Vec3b> colors(nccomps+1);
		  colors[0] = cv::Vec3b(0,0,0); // background pixels remain black.
		  img_color = cv::Mat::zeros(arnold.size(), CV_8UC3);
		  for( i = 1; i <= nccomps; i++ ) {
		    colors[i] = cv::Vec3b(rand()%256, rand()%256, rand()%256);
		    cout << "A:W:H" << stats.at<int>(i-1, cv::CC_STAT_AREA) << ":" << stats.at<int>(i-1, cv::CC_STAT_WIDTH) << ":" << stats.at<int>(i-1, cv::CC_STAT_HEIGHT);
		   
			
		    if( stats.at<int>(i-1, cv::CC_STAT_AREA) < 50 ||  stats.at<int>(i-1, cv::CC_STAT_WIDTH) >400 || stats.at<int>(i-1, cv::CC_STAT_HEIGHT) > 400 ){
			cout << "excluded " << endl;
		    	colors[i] = cv::Vec3b(0,0,0); // small regions are painted with black too.
			filteredcomponents--;
			}//end if fail filters
		  }//end for each nccomp
		
		  for( int y = 0; y < img_color.rows; y++ )
		    for( int x = 0; x < img_color.cols; x++ )
		    {
		      int label = labels.at<int>(y, x);
		      CV_Assert(0 <= label && label <= nccomps);
		      img_color.at<cv::Vec3b>(y, x) = colors[label];
		    }

		FileStorage fs;
		fs.open("components.json",FileStorage::WRITE | FileStorage::FORMAT_JSON);
		fs.write("stats",stats);
		fs.write("cents",centroids);		 

		for( i = 1; i <= nccomps; i++ ) {
			 double centx,centy=0;
			centx=centroids.at<double>(i-1, 0);
			centy=centroids.at<double>(i-1, 1);
			
			
			stringstream cs;
			cs << i-1;
			putText(img_color, cs.str() , cvPoint(centx,centy),FONT_HERSHEY_COMPLEX_SMALL, 0.8, cvScalar(200,200,250), 1, CV_AA);
		}//end for each component

		imwrite("Labeledmap.png", img_color);
		fs.release();
		cout << "Filtered Connected Components: " << filteredcomponents << endl;	



            return;
        }


	


        //update the background model
      //  pMOG2->apply(myframe, fgMaskMOG2,learningrate);
        //get the frame number and write it on the current frame
        stringstream ss;
      
        //show the current frame and the fg masks
       
       // imshow("FG Mask MOG 2", fgMaskMOG2);


	//make the background mask
	Mat canny_output;
	vector<vector<Point> > contours;
	vector<Vec4i> hierarchy;
	blur( myframe, myframe, Size(5,5) );						
	Canny( myframe, canny_output, 80, 180, 3 );
	findContours( canny_output, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point(0, 0) );
	Mat drawing = (Mat::zeros( canny_output.size(), CV_8UC1 ));

	


	for( size_t j = 0; j< contours.size(); j++ )
		 {
		  
		   Scalar color = SCALAR_WHITE;
		   drawContours( drawing, contours, (int)j, color, 1, 8, hierarchy, 0, Point() );


		 }

	if (firstframe) {
		deathmask = drawing.clone();
		arnold= drawing.clone();
		firstframe=false;
	}

	drawing = drawing - deathmask;
	arnold = arnold + drawing;
	Mat black = (Mat::zeros( myframe.size(), CV_8UC1 ));//set green to black

	
	vector<Mat>  compchannels(3);
	compchannels.at(0) = arnold;
	compchannels.at(1) =   deathmask;
	compchannels.at(2) = drawing;
	merge(compchannels,coloroutput);
	

	
	//addWeighted(lastrun,0.4,myframe,0.6,0.0,blended);
			   


	
	 
	// Show blobs
	//imshow("keypoints", im_with_keypoints );
	



	//imshow("Frame", blended);
	//imshow("Simple Ass BS", coloroutput);
	stringstream sss;
	sss << "lastimage_day" << daynum << ".png";
	imwrite(sss.str().c_str(),coloroutput);
	//output << blended;
        //get the input from the keyboard
        keyboard = waitKey( 1 );
    }
    //delete capture object
    capture.release();
/*  
  capture.open(videoFilename);


    if(!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open video file: " << videoFilename << endl;
        exit(EXIT_FAILURE);
    }


	// open output
	VideoWriter output;
	stringstream filename;
	filename << "merged.avi";
	Size size = coloroutput.size();

	output.open(filename.str().c_str(), VideoWriter::fourcc('M', 'P', '4', '2'),
			capture.get(CAP_PROP_FPS), size, true);

	if (!output.isOpened()) {
		cout << "Could not open the output video for write" << endl;
		return;
	}

	 while( (char)keyboard != 'q' && (char)keyboard != 27 ){
		//read the current frame
		if(!capture.read(myframe)) {
		    cerr << "Unable to read next frame." << endl;
		    cerr << "Exiting..." << endl;
		    exit(EXIT_FAILURE);
		} else {
			
			
			output << blended;
			imshow("Simple Ass BS", blended);

		}//end if frame good
	}//end while not stopped

*/		







	


}//end process vid




void processImages(char* fistFrameFilename) {
    //read the first file of the sequence
    myframe = imread(fistFrameFilename);
    if(myframe.empty()){
        //error in opening the first image
        cerr << "Unable to open first image frame: " << fistFrameFilename << endl;
        exit(EXIT_FAILURE);
    }
    //current image filename
    string fn(fistFrameFilename);
    //read input data. ESC or 'q' for quitting
    while( (char)keyboard != 'q' && (char)keyboard != 27 ){
        //update the background model
        pMOG2->apply(myframe, fgMaskMOG2);
        //get the frame number and write it on the current frame
        size_t index = fn.find_last_of("/");
        if(index == string::npos) {
            index = fn.find_last_of("\\");
        }
        size_t index2 = fn.find_last_of(".");
        string prefix = fn.substr(0,index+1);
        string suffix = fn.substr(index2);
        string frameNumberString = fn.substr(index+1, index2-index-1);
        istringstream iss(frameNumberString);
        int frameNumber = 0;
        iss >> frameNumber;
        rectangle(myframe, cv::Point(10, 2), cv::Point(100,20),
                  cv::Scalar(255,255,255), -1);
        putText(myframe, frameNumberString.c_str(), cv::Point(15, 15),
                FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
        //show the current frame and the fg masks
        imshow("Frame", myframe);
        imshow("FG Mask MOG 2", fgMaskMOG2);
        //get the input from the keyboard
        keyboard = waitKey( 30 );
        //search for the next image in the sequence
        ostringstream oss;
        oss << (frameNumber + 1);
        string nextFrameNumberString = oss.str();
        string nextFrameFilename = prefix + nextFrameNumberString + suffix;
        //read the next frame
        myframe = imread(nextFrameFilename);
        if(myframe.empty()){
            //error in opening the next image in the sequence
            cerr << "Unable to open image frame: " << nextFrameFilename << endl;
            exit(EXIT_FAILURE);
        }
        //update the path of the current frame
        fn.assign(nextFrameFilename);
    }
}

